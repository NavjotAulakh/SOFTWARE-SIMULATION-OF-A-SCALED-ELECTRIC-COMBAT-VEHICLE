1. Problem Identification (3%) - Nico 
The main scope of the project is to design and implement an algorithm for the Electrical combat vehicle that will classify and detect obstacles on ground in the real world with the 8x8 prototype. 
The main focus of the algorithm is to have a quick reaction in a minimum timeframe possible.  To implement this classification algorithm we will have to first create a simulated environment with the ROS (Robot Operation System), 
test it and validate the algorithm, and  then test it physically with the prototype on the real world.

2. Project-related Background and Research Review (3%) - Nico
For the background and research required for the implementation and build of the environment  it’s important to take count with the set of packages available of ROS, such as GAZEBO which will have the all the interfaces require
for the simulation of the environment and then so apply the obstacle algorithms to the navigation system in the respective environment.  For the development of the environment and the simulation of the algorithm all the group members 
would require to learn and to get involved with multiple navigation and manipulation packages such as husky simulation.

3. Design Process (3%) - nav
The project requires a robust solution for the image processing algorithm, which must accompanied by a thorough testing phase and 
implemented according to the requirement specifications. This aspect of the project requires the design process to follow a strict 
one way model, and the most robust process model that is built up from provided requirement specifications is the Waterfall Model. 
This model is considered the oldest of the structured SDLC methodologies, but has a very simple approach where you first finish one 
phase and then most on to the next without ever going back. Each of the stages are built upon the previous stages and has its own 
project plan. For this algorithm, it’s crucial that the requirements are first thoroughly researched, and documented. 

4. Scenarios and/or Use Cases (5%) - nav

5. Stakeholder Requirements and Traceability Matrix (10%) - Jeffrey

| Req ID#	| Req Type	| Requirement Source	| Requirement Specification |
| ------------- | ------------- | ------------- | ------------- |
| RQ1 | Client | This project requires students to design and develop an image processing algorithm..	| The development of an object detection algorithm (ODA) is integral to the project. |
| RQ2	| Client | …that can detect and classify objects and obstacles for the 8x8 Electric Combat Vehicle. | ODA must be able to identify and categorize individual objects in a real environment. |
| RQ3	| Client | Such techniques may include, but is not limited to, convolutional neural networks and other deep learning options. | ODA must be capable of identifying a large variety of objects, both large and small scale. |
| RQ4 | Client | …The algorithm must be compatible with ROS (Robot Operating System) | ODA must support an interface that the ROS architecture can utilize. |
| RQ5 | Client | The algorithm should be efficient and robust and must exhibit high repeatability.” | ODA must perform its tasks in an acceptable amount of time, and must operate in a stable state machine framework. Since ROS does not operate in real time, neither can ODA. |
| RQ6 | Client | Sourcing of compatible sensors and controller hardware for compact packaging and deployment. | ODA must utilize sensors and controllers that is compatible with ROS. |
| RQ7 | Client | Write C++/Python code for Obstacle Detection and Classification | ODA must be developed to be compatible with ROS, so it must be written in either Python or C++ as the programming language. |
| RQ8 | Client | Conduct testing and validation in both simulated and physical environment. | ODA must support both simulated and physical implementation of the algorithm. The ODA must support testing and debugging in both simulated and physical environments. |
Table 1-5A – Requirements Specification

| Test Case ID#	| Quality Attribute | Test Case Description |
| ------------- | ------------- | ------------- |
| TC1 | Compatibility | ODA is accessible by any ROS localization algorithm through a generic interface to generate robot localization. |
| TC2 | Functional Suitability | ODA will properly identify all distinct objects in the environment. |
| TC3 | Functional Suitability | ODA will properly categorize objects into Impassable, Passable, and Distant. |
| TC4 | Functional Suitability | ODA should be able to operate with its full feature set in Gazebo, a simulation software environment. |
| TC5 | Functional Suitability | ODA should be able to operate with its full feature set when implemented on a ROS compatible hardware device. |
| TC6 | Performance Efficiency | ODA will complete a designated course in relatively the same amount of time as a comparable laser-based implementation of an object detection algorithm. |
| TC7 | Usability | ODA should not require any extra user interaction besides installation. |
| TC8 | Reliability | ODA should operate in a stable state machine and continue running indefinitely. |
| TC9 | Reliability | ODA should be able to detect and recover from object detection related faults, and sensor disability faults. |
| TC10 | Security | ODA should not be an accessible security attack surface. |
| TC11 | Maintainability | ODA should be a modular algorithm that can be easily transplanted into new robotic devices that support ROS |
| TC12 | Portability | ODA installation should not require much more time to install then ROS alone. It should be an includable library. |
Table 1-5B – Test Case Description

| Test Cases \ Requirements | RQ1 | RQ2 | RQ3 | RQ4 | RQ5 | RQ6 | RQ7 | RQ8 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| TC1  |   |   |   | X |   |   | X | X |
| TC2  | X | X | X |   |   |   |   |   |
| TC3  | X | X | X |   |   |   |   |   |
| TC4  | X |   | X | X |   |   | X | X |
| TC5  | X | X | X |   |   | X |   | X |
| TC6  |   |   |   |   | X |   |   |   |
| TC7  | X |   |   | X |   |   |   |   |
| TC8  |   |   |   |   | X |   |   |   |
| TC9  |   |   |   |   |   |   | X | X |
| TC10 |   |   |   |   | X |   |   |   |
| TC11 |   |   |   |   |   | X |   | X |
| TC12 |   |   |   |   |   | X |   | X |
Table 1-5C - Requirements Tractability Table

6. Definition of Acceptance Tests (3%) - Soso

7. Project Plan (3%)- Soso

8. Contribution matrix 
